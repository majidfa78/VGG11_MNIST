{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader,random_split\n",
        "import torch.nn.functional as F"
      ],
      "metadata": {
        "id": "ohMyM3hdq5hg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C21M2Tkbqo-6"
      },
      "outputs": [],
      "source": [
        "# Define the VGG11 model\n",
        "class VGG11(nn.Module):\n",
        "    def __init__(self, num_classes=10):  # Defaulting to 10 classes for MNIST\n",
        "        super(VGG11, self).__init__()\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(1, 64, kernel_size=3, padding=1),  # Input: 1 channel (grayscale)\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),       # Output: 64 channels\n",
        "\n",
        "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),       # Output: 128 channels\n",
        "\n",
        "            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),       # Output: 256 channels\n",
        "\n",
        "            nn.Conv2d(256, 512, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),       # Output: 512 channels\n",
        "\n",
        "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),       # Output: 512 channels\n",
        "        )\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(512 * 1 * 1, 4096),  # Adjust input size if needed for the dataset\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(4096, 4096),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(4096, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        # Flatten the tensor\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.classifier(x)\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "XELV_yA-rAOG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data loading and preprocessing\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((32, 32)),  # Resize to fit AlexNet input size\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))\n",
        "])\n",
        "\n",
        "train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "train_set, val_set = random_split(train_dataset, [0.9, 0.1])\n",
        "train_loader = DataLoader(dataset=train_set, batch_size=2048, shuffle=True)\n",
        "val_loader = DataLoader(dataset=val_set, batch_size=2048, shuffle=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XcO532q_rDeG",
        "outputId": "e64cdb8d-4a82-4394-90e2-cba0a53d5306"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:02<00:00, 3.64MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 68.6kB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1.65M/1.65M [00:07<00:00, 220kB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 8.69MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Instantiate the VGG11 model\n",
        "model = VGG11(num_classes=10).to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "kd5cxtZPrpmt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training loop\n",
        "num_epochs = 10\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for idx,(images, labels) in enumerate(train_loader):#train\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        if(idx % 5 == 0):\n",
        "          print(f'batch:{idx} , batch loss:{loss.item()}\\n')\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    acc=0\n",
        "    for idx,(images, labels) in enumerate(val_loader): #validation\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = torch.argmax(model(images),dim=1)\n",
        "        comp=torch.eq(labels,outputs).float().to('cpu')\n",
        "        acc+=torch.sum(comp)/len(comp)\n",
        "\n",
        "    print(f'Epoch [{epoch + 1}/{num_epochs}], Total loss: {total_loss / len(train_loader):.4f} , Accuracy : {acc/(idx+1)} %')\n",
        "\n",
        "print(\"Training complete!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9gClQpXlrF9u",
        "outputId": "ad1dbdae-a747-474e-87ed-d95237432cf4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "batch:0 , batch loss:1.2753186225891113\n",
            "\n",
            "batch:5 , batch loss:1.2636518478393555\n",
            "\n",
            "batch:10 , batch loss:1.1441742181777954\n",
            "\n",
            "batch:15 , batch loss:1.0533167123794556\n",
            "\n",
            "batch:20 , batch loss:1.000481128692627\n",
            "\n",
            "batch:25 , batch loss:0.844616174697876\n",
            "\n",
            "Epoch [1/10], Total loss: 1.0791 , Accuracy : 0.6438227295875549 %\n",
            "batch:0 , batch loss:0.8499715924263\n",
            "\n",
            "batch:5 , batch loss:0.8145959973335266\n",
            "\n",
            "batch:10 , batch loss:0.7073031067848206\n",
            "\n",
            "batch:15 , batch loss:0.7828456163406372\n",
            "\n",
            "batch:20 , batch loss:0.6111133694648743\n",
            "\n",
            "batch:25 , batch loss:0.6415795683860779\n",
            "\n",
            "Epoch [2/10], Total loss: 0.7277 , Accuracy : 0.7794063091278076 %\n",
            "batch:0 , batch loss:0.5823383927345276\n",
            "\n",
            "batch:5 , batch loss:0.6215003728866577\n",
            "\n",
            "batch:10 , batch loss:0.5152417421340942\n",
            "\n",
            "batch:15 , batch loss:0.4505057632923126\n",
            "\n",
            "batch:20 , batch loss:0.44711658358573914\n",
            "\n",
            "batch:25 , batch loss:0.38825684785842896\n",
            "\n",
            "Epoch [3/10], Total loss: 0.4951 , Accuracy : 0.8931963443756104 %\n",
            "batch:0 , batch loss:0.38049063086509705\n",
            "\n",
            "batch:5 , batch loss:0.3259909749031067\n",
            "\n",
            "batch:10 , batch loss:0.32180699706077576\n",
            "\n",
            "batch:15 , batch loss:0.20260733366012573\n",
            "\n",
            "batch:20 , batch loss:0.16840240359306335\n",
            "\n",
            "batch:25 , batch loss:0.17621654272079468\n",
            "\n",
            "Epoch [4/10], Total loss: 0.2461 , Accuracy : 0.9476499557495117 %\n",
            "batch:0 , batch loss:0.16156108677387238\n",
            "\n",
            "batch:5 , batch loss:0.11868008226156235\n",
            "\n",
            "batch:10 , batch loss:0.14147354662418365\n",
            "\n",
            "batch:15 , batch loss:0.1569417119026184\n",
            "\n",
            "batch:20 , batch loss:0.12990161776542664\n",
            "\n",
            "batch:25 , batch loss:0.1251712143421173\n",
            "\n",
            "Epoch [5/10], Total loss: 0.1433 , Accuracy : 0.959526002407074 %\n",
            "batch:0 , batch loss:0.12251082807779312\n",
            "\n",
            "batch:5 , batch loss:0.1019994467496872\n",
            "\n",
            "batch:10 , batch loss:0.08200325816869736\n",
            "\n",
            "batch:15 , batch loss:0.10989931970834732\n",
            "\n",
            "batch:20 , batch loss:0.10112489014863968\n",
            "\n",
            "batch:25 , batch loss:0.07415781915187836\n",
            "\n",
            "Epoch [6/10], Total loss: 0.0980 , Accuracy : 0.9675354957580566 %\n",
            "batch:0 , batch loss:0.08328837156295776\n",
            "\n",
            "batch:5 , batch loss:0.08534689992666245\n",
            "\n",
            "batch:10 , batch loss:0.10034552961587906\n",
            "\n",
            "batch:15 , batch loss:0.07768497616052628\n",
            "\n",
            "batch:20 , batch loss:0.08057639002799988\n",
            "\n",
            "batch:25 , batch loss:0.07756669074296951\n",
            "\n",
            "Epoch [7/10], Total loss: 0.0794 , Accuracy : 0.9775500297546387 %\n",
            "batch:0 , batch loss:0.05646264925599098\n",
            "\n",
            "batch:5 , batch loss:0.052515823394060135\n",
            "\n",
            "batch:10 , batch loss:0.08430726081132889\n",
            "\n",
            "batch:15 , batch loss:0.054033465683460236\n",
            "\n",
            "batch:20 , batch loss:0.06418054550886154\n",
            "\n",
            "batch:25 , batch loss:0.05525539815425873\n",
            "\n",
            "Epoch [8/10], Total loss: 0.0611 , Accuracy : 0.9813523292541504 %\n",
            "batch:0 , batch loss:0.04141971096396446\n",
            "\n",
            "batch:5 , batch loss:0.04061271622776985\n",
            "\n",
            "batch:10 , batch loss:0.04003724083304405\n",
            "\n",
            "batch:15 , batch loss:0.05885223671793938\n",
            "\n",
            "batch:20 , batch loss:0.04950924590229988\n",
            "\n",
            "batch:25 , batch loss:0.04419897869229317\n",
            "\n",
            "Epoch [9/10], Total loss: 0.0502 , Accuracy : 0.9817270636558533 %\n",
            "batch:0 , batch loss:0.032698847353458405\n",
            "\n",
            "batch:5 , batch loss:0.04583631083369255\n",
            "\n",
            "batch:10 , batch loss:0.033469170331954956\n",
            "\n",
            "batch:15 , batch loss:0.039642881602048874\n",
            "\n",
            "batch:20 , batch loss:0.04006074741482735\n",
            "\n",
            "batch:25 , batch loss:0.03764987736940384\n",
            "\n",
            "Epoch [10/10], Total loss: 0.0408 , Accuracy : 0.9831795692443848 %\n",
            "Training complete!\n"
          ]
        }
      ]
    }
  ]
}